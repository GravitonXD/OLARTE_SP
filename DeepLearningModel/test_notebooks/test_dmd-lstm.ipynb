{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from pydmd import DMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of data: 5675\n",
      "Closing Prices: [2141.77 2153.18 2074.75 ... 6923.08 6842.79 6876.79]\n"
     ]
    }
   ],
   "source": [
    "# Import data from data/PSEI.csv to numpy array\n",
    "# Get only the closing price (usecols=4)\n",
    "data = np.genfromtxt('data/PSEI.csv', delimiter=',', skip_header=1, usecols=4)\n",
    "print(f\"Length of data: {len(data)}\")\n",
    "print(f\"Closing Prices: {data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of data_train: 4540\n",
      "Data Train: [2141.77 2153.18 2074.75 ... 7267.34 7348.42 7233.57]\n",
      "\n",
      "Length of data_test: 1135\n",
      "Data Test: [7186.71 7186.62 7233.29 ... 6923.08 6842.79 6876.79]\n"
     ]
    }
   ],
   "source": [
    "# Split data into training and testing\n",
    "len_train = int(len(data) * 0.80)\n",
    "data_train = data[:len_train]\n",
    "print(f\"Length of data_train: {len(data_train)}\\nData Train: {data_train}\\n\")\n",
    "data_test = data[len_train:]\n",
    "print(f\"Length of data_test: {len(data_test)}\\nData Test: {data_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "input_dim = 3\n",
    "hidden_dim = 5\n",
    "num_layers = 1\n",
    "output_dim = 1\n",
    "num_epochs = 100\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: [2141.77 2153.18 2074.75]\n",
      "X.shape: (4538, 3)\n"
     ]
    }
   ],
   "source": [
    "X = np.zeros(((len(data_train)-(input_dim-1)), input_dim))\n",
    "for i in range(len(X)):\n",
    "    X[i, 0:input_dim] = data_train[i:i+input_dim]\n",
    "print(f\"X: {X[0]}\")\n",
    "print(f\"X.shape: {X.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic Mode: [[-0.00667728 -0.02347301]\n",
      " [-0.00671106  0.00118711]\n",
      " [-0.00676263  0.0044092 ]\n",
      " ...\n",
      " [-0.02346365  0.01133992]\n",
      " [-0.02373525  0.02375659]\n",
      " [-0.02331795 -0.03459818]]\n",
      "Length of Dynamic Mode: (4538, 2)\n"
     ]
    }
   ],
   "source": [
    "dmd = DMD(svd_rank=2, exact=True)\n",
    "dmd.fit(X)\n",
    "dynamic_mode = dmd.modes\n",
    "print(f\"Dynamic Mode: {dynamic_mode}\")\n",
    "print(f\"Length of Dynamic Mode: {dynamic_mode.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: [[2141.77 2153.18 2074.75]\n",
      " [2153.18 2074.75 2079.11]\n",
      " [2074.75 2079.11 2094.29]\n",
      " ...\n",
      " [7193.68 7227.96 7267.34]\n",
      " [7227.96 7267.34 7348.42]\n",
      " [7267.34 7348.42 7233.57]]\n",
      "y: 4537\n"
     ]
    }
   ],
   "source": [
    "# prepare data for LSTM input\n",
    "for i in range(len(X)):\n",
    "    X[i, input_dim:] = dynamic_mode[i, 0]\n",
    "y = data_train[input_dim:]\n",
    "print(f\"X: {X}\")\n",
    "print(f\"y: {len(y)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up LSTM model\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x.view(len(x), 1, -1))\n",
    "        y_pred = self.fc(lstm_out[-1].view(1, -1))\n",
    "        return y_pred.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data to PyTorch tensors\n",
    "X = torch.Tensor(X)\n",
    "y = torch.Tensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up LSTM model and optimizer\n",
    "model = LSTM(input_dim, hidden_dim, output_dim)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\johnm\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([4537])) that is different to the input size (torch.Size([1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss 21172332.0\n",
      "Epoch 10, Loss 21170174.0\n",
      "Epoch 20, Loss 21168012.0\n",
      "Epoch 30, Loss 21165854.0\n",
      "Epoch 40, Loss 21163694.0\n",
      "Epoch 50, Loss 21161532.0\n",
      "Epoch 60, Loss 21159374.0\n",
      "Epoch 70, Loss 21157214.0\n",
      "Epoch 80, Loss 21155056.0\n",
      "Epoch 90, Loss 21152900.0\n"
     ]
    }
   ],
   "source": [
    "# train the LSTM model\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    y_pred = model(X)\n",
    "    loss = nn.MSELoss()(y_pred, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted closing price: 2.222327470779419\n",
      "Actual closing price: 7333.73\n"
     ]
    }
   ],
   "source": [
    "# make a prediction for the next closing price\n",
    "X_test = np.zeros((1, input_dim))\n",
    "X_test[0, 0:input_dim] = data_test[0:input_dim]\n",
    "X_test[0, input_dim:] = dynamic_mode[-1, 0]\n",
    "X_test = torch.Tensor(X_test)\n",
    "y_pred = model(X_test)\n",
    "print(f\"Predicted closing price: {y_pred.item()}\")\n",
    "print(f\"Actual closing price: {data_test[input_dim]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (2,) into shape (3,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m X_pred[\u001b[39m0\u001b[39m, input_dim:] \u001b[39m=\u001b[39m dynamic_mode[\u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m]\n\u001b[0;32m      7\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39mlen\u001b[39m(X_pred)):\n\u001b[1;32m----> 8\u001b[0m     X_pred[i, \u001b[39m0\u001b[39;49m:input_dim] \u001b[39m=\u001b[39m X_pred[i\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m:input_dim\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[0;32m      9\u001b[0m     X_pred[i, input_dim:] \u001b[39m=\u001b[39m dynamic_mode[i\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m]\n\u001b[0;32m     10\u001b[0m X_pred \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mTensor(X_pred)\n",
      "\u001b[1;31mValueError\u001b[0m: could not broadcast input array from shape (2,) into shape (3,)"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Predict all X\n",
    "X_pred = np.zeros((len(data_train), input_dim))\n",
    "X_pred[0, 0:input_dim] = data_train[0:input_dim]\n",
    "X_pred[0, input_dim:] = dynamic_mode[0, 0]\n",
    "for i in range(1, len(X_pred)):\n",
    "    X_pred[i, 0:input_dim] = X_pred[i-1, 1:input_dim+1]\n",
    "    X_pred[i, input_dim:] = dynamic_mode[i-1, 0]\n",
    "X_pred = torch.Tensor(X_pred)\n",
    "y_pred = model(X_pred)\n",
    "print(f\"Predicted closing price: {y_pred}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c73b41b33398381a63dda394fd0b0cb02413d3de08933cb9c9d1d83148e4d367"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
